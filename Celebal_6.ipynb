{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fe39ab-f74c-423e-94ef-b5c1db50638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ba6220-0ae5-4b41-9c2f-852525d5121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd904f8d-4a7f-49de-b2d1-bc98623dd67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "4          Naive Bayes  0.973684   0.959459  1.000000  0.979310\n",
      "1        Random Forest  0.964912   0.958904  0.985915  0.972222\n",
      "0  Logistic Regression  0.956140   0.945946  0.985915  0.965517\n",
      "2                  SVM  0.947368   0.922078  1.000000  0.959459\n",
      "3        Decision Tree  0.929825   0.943662  0.943662  0.943662\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Evaluate all models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b574364f-130e-4461-bf6d-9fb8a77a5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params (GridSearchCV): {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(\"Best RF Params (GridSearchCV):\", grid_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3c619f-2ecb-48e1-80d0-e27b5c4a488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Params (RandomizedSearchCV): {'kernel': 'linear', 'gamma': 0.01, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "param_dist_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "random_svc = RandomizedSearchCV(SVC(), param_distributions=param_dist_svc, n_iter=10, scoring='f1', cv=5, n_jobs=-1)\n",
    "random_svc.fit(X_train, y_train)\n",
    "print(\"Best SVC Params (RandomizedSearchCV):\", random_svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3f741b-79f4-48bd-b28e-bb5654391611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Tuned Random Forest  0.964912   0.958904  0.985915  0.972222\n",
      "1            Tuned SVC  0.956140   0.945946  0.985915  0.965517\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned RF\n",
    "best_rf = grid_rf.best_estimator_\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate tuned SVC\n",
    "best_svc = random_svc.best_estimator_\n",
    "svc_pred = best_svc.predict(X_test)\n",
    "\n",
    "# Compare with original results\n",
    "tuned_results = [\n",
    "    {\n",
    "        \"Model\": \"Tuned Random Forest\",\n",
    "        \"Accuracy\": accuracy_score(y_test, rf_pred),\n",
    "        \"Precision\": precision_score(y_test, rf_pred),\n",
    "        \"Recall\": recall_score(y_test, rf_pred),\n",
    "        \"F1 Score\": f1_score(y_test, rf_pred)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Tuned SVC\",\n",
    "        \"Accuracy\": accuracy_score(y_test, svc_pred),\n",
    "        \"Precision\": precision_score(y_test, svc_pred),\n",
    "        \"Recall\": recall_score(y_test, svc_pred),\n",
    "        \"F1 Score\": f1_score(y_test, svc_pred)\n",
    "    }\n",
    "]\n",
    "\n",
    "df_tuned_results = pd.DataFrame(tuned_results)\n",
    "print(df_tuned_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa9f145-fb61-4e38-92bf-66b984c68cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Final Model Comparison:\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0          Naive Bayes  0.973684   0.959459  1.000000  0.979310\n",
      "1        Random Forest  0.964912   0.958904  0.985915  0.972222\n",
      "5  Tuned Random Forest  0.964912   0.958904  0.985915  0.972222\n",
      "2  Logistic Regression  0.956140   0.945946  0.985915  0.965517\n",
      "6            Tuned SVC  0.956140   0.945946  0.985915  0.965517\n",
      "3                  SVM  0.947368   0.922078  1.000000  0.959459\n",
      "4        Decision Tree  0.929825   0.943662  0.943662  0.943662\n"
     ]
    }
   ],
   "source": [
    "final_results = pd.concat([df_results, df_tuned_results], ignore_index=True).sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(\"ðŸ“Š Final Model Comparison:\")\n",
    "print(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71528eb4-0ed8-4a47-ae7f-73daa2424526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Performing Model: Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "best_model_name = final_results.iloc[0]['Model']\n",
    "print(f\"âœ… Best Performing Model: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb31642-d29a-4201-a8d4-9a0141419a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.96      1.00      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if best_model_name == \"Tuned Random Forest\":\n",
    "    print(classification_report(y_test, rf_pred))\n",
    "elif best_model_name == \"Tuned SVC\":\n",
    "    print(classification_report(y_test, svc_pred))\n",
    "else:\n",
    "    print(classification_report(y_test, models[best_model_name].predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd7e497-b316-44ee-9417-c0004c517e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Comparison:\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0          Naive Bayes  0.973684   0.959459  1.000000  0.979310\n",
      "1        Random Forest  0.964912   0.958904  0.985915  0.972222\n",
      "2  Logistic Regression  0.956140   0.945946  0.985915  0.965517\n",
      "3            Tuned SVC  0.956140   0.945946  0.985915  0.965517\n",
      "4  Tuned Random Forest  0.956140   0.958333  0.971831  0.965035\n",
      "5                  SVM  0.947368   0.922078  1.000000  0.959459\n",
      "6        Decision Tree  0.938596   0.944444  0.957746  0.951049\n",
      "\n",
      "âœ… Best Performing Model: Naive Bayes\n",
      "\n",
      "Classification Report of Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.96      1.00      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 1. Load and prepare the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train and evaluate base models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# 3. Hyperparameter tuning for Random Forest using GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Hyperparameter tuning for SVM using RandomizedSearchCV\n",
    "param_dist_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "random_svc = RandomizedSearchCV(SVC(), param_distributions=param_dist_svc, n_iter=10, scoring='f1', cv=5, n_jobs=-1)\n",
    "random_svc.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate tuned models\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_svc = random_svc.best_estimator_\n",
    "\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "svc_pred = best_svc.predict(X_test)\n",
    "\n",
    "tuned_results = [\n",
    "    {\n",
    "        \"Model\": \"Tuned Random Forest\",\n",
    "        \"Accuracy\": accuracy_score(y_test, rf_pred),\n",
    "        \"Precision\": precision_score(y_test, rf_pred),\n",
    "        \"Recall\": recall_score(y_test, rf_pred),\n",
    "        \"F1 Score\": f1_score(y_test, rf_pred)\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Tuned SVC\",\n",
    "        \"Accuracy\": accuracy_score(y_test, svc_pred),\n",
    "        \"Precision\": precision_score(y_test, svc_pred),\n",
    "        \"Recall\": recall_score(y_test, svc_pred),\n",
    "        \"F1 Score\": f1_score(y_test, svc_pred)\n",
    "    }\n",
    "]\n",
    "\n",
    "df_tuned = pd.DataFrame(tuned_results)\n",
    "\n",
    "# 6. Final results and best model selection\n",
    "final_df = pd.concat([df_results, df_tuned], ignore_index=True)\n",
    "final_df = final_df.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(\"Final Model Comparison:\\n\")\n",
    "print(final_df)\n",
    "\n",
    "# 7. Best model\n",
    "best_model_name = final_df.iloc[0][\"Model\"]\n",
    "print(f\"\\nâœ… Best Performing Model: {best_model_name}\")\n",
    "\n",
    "# 8. Print classification report of best model\n",
    "print(\"\\nClassification Report of Best Model:\")\n",
    "if best_model_name == \"Tuned Random Forest\":\n",
    "    print(classification_report(y_test, rf_pred))\n",
    "elif best_model_name == \"Tuned SVC\":\n",
    "    print(classification_report(y_test, svc_pred))\n",
    "else:\n",
    "    best_model = models[best_model_name]\n",
    "    y_pred_best = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cb3fe-f300-41a5-bed1-4dcd388d1072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
